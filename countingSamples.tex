\section{Counting Samples}
Counting samples is another approach presented by Gibbons and Matias
\cite{GM98}. The idea is similar to the one behind the concise
samples. The definition of the $count$ is refined. Namely, the counts
are used to track all occurrences of a value inserted into the
relation since the value was selected for the sample. The counting
samples might be understood as the random experiment in which for each
attribute value that occurs $c$ times in relation $R$ the biased coin
with probability of heads $\frac{1}{\tau}$ is flipped till the first
head. If we denote by $i$ the number of tosses till the first head
then the $count$ equals $c - i + 1$. If there is no head in $c$ throws
then the value does not show up in the sample. Similarly as for the
concise sample the value for which count is greater than one is
represented as a pair $\langle value, count \rangle$. Values for
which count is exactly one are represented by singleton
$value$. Clearly, the values for which count is zero are not
represented in the sample. The counting samples are not uniformly
distributed but it is possible to obtain concise sample from counting
samples. To do that, it is enough to toss a biased coin with head
probability $\frac{1}{\tau}$ $count - 1$ times. The concise sample is
the counting sample for which the $coutn$ is reduced by the number of
tails in the above random experiment. Obviously, if the $count$ is
reduced to one, sample is represented by a singleton. Similarly, if the
$count$ is reduced to zero the sample is not represented.

\subsection{Incremental algorithm for maintenance of counting samples}
Similarly as it was in the  case of concise samples Gibbons and Matias
propose an algorithm for maintaining samples in presence of inserts to
data warehouse. The algorithm was briefly presented on the following
code excerpt

\begin{center}
  \captionof{algorithm}{Incremental maintenance of counting samples}\label{alg:maintenace-counting-samples}
  \begin{algorithmic}
  \Function{InsertTuple}{$t$}
  \If{$t.A$ is a pair $\langle value, count \rangle$ in $S$}
  \State Increment by one $count$ in $\langle value, count \rangle$
  \ElsIf{$t.A$ is a singleton in $S$}
  \State Remove singleton $value$ corresponding to $t.A$ from $S$
  \State Insert $\langle t.A, 2 \rangle$ into $S$
  \ElsIf{$t.A$ is not present in $S$}
  \State {Add $t.A$ as singleton value with propbability $\frac{1}{\tau}$}
  \EndIf
  \If{$footprint(S) > m$}
  \State {MakeSpace()}
  \EndIf
  \EndFunction
  \State{}
  %MakeSpace function
  \Function{MakeSpace}{}
  \State{Raise threshold to $\tau'$}
  \ForAll{s in $S$}
  \State{$count' = 0$}
  \State {Flip a coin with probability of head $\frac{\tau}{\tau'}$}
  \While{Tail is flipped}
  \State{$count' \gets count' + 1$}
  \EndWhile
  \State{$s.count \gets s.count - count'$ }
  \If{$s.count = 0$}
  \State{Remove $s$ from $S$}
  \ElsIf{$c.count = 1$ and $s$ is a pair}
  \State{Remove $s$ from $S$}
  \State{Insert singleton corresponding to $s$ into $S$}
  \Else
  \State{Update the pair corresponding to $s$ with new $count$ value}
  \EndIf
  \EndFor
  \EndFunction
\end{algorithmic}
\end{center}

As one can see this algorithm is similar to the one already described
for concise samples. Careful reader might observed that we did not
provided any solution for concise samples in case when tuples are delated from data
warehouse. Actually this is the motivation for
introducing the counting samples. Delating concise samples is hard. If
the delation is omitted, it is possible that there exists a representation of
a tuple in the sample but this tuple is no longer present in the data
warehouse. On contrary if we update or remove sample on each delation,
the sample representation is no longer a distribution that
corresponds to the one of data stored in data warehouse.
This is the motivation for introducing counting samples.
Gibbons and Matias \cite{GM98} prove the following theorem for counting samples:

\begin{theorem}
The algorithm \textbf{Algorithm \ref{alg:maintenace-counting-samples}}
for any sequence of insertions and deletions maintain properties of
counting samples.
\end{theorem}
\begin{proof}
  For insertions the properties of counting samples are trivially
  fulfilled. Namely, in case when tuple is present in the samples, we
  the count is incremented by one. When, tuple is not present in the
  samples, the algorithm flips a coin to check whether the tuple
  should be added to the samples.
  %TODO what in the case when footprint is too ?

  Similarly for a delation of value $v$ from the relation two cases
  have to be considered. In the first one, when value is represented
  in the counting sample then the count is decremented. It may fall
  till 0, then the value is removed. It might also drop to 1, when the
  value representation is changed into the singleton. In case the
  value is not present in the sample then it might be simply omitted.

  In case of raising the threshold from $\tau$ to $\tau'$ Gibbons and
  Matias claim that if the value is not in the sample, which means
  that $c$ coin flips came up tails, then it should also not be in the
  sample after increasing the threshold. In the situation when a value
  is represented in the sample and its count is $c'$, then we know
  that for $c - c'$ tails were flipped. As we raised the threshold
  the outcome of this flips should remain unchanged. Then in the next
  coin toss the head is observed. We redo the flip with the head
  probability $\frac{\tau}{\tau'}$. Hence, we have that probability of
  obtaining a head in this random experiment is
  \begin{align*}
    P \left(  \text{the result of a coin toss is head} \right) =
    \frac{\tau}{\tau'} \cdot \frac{1}{\tau} = \frac{1}{\tau'}.
  \end{align*}
  If the outcome of this coin toss is tail, we continue to flip
  till the first head (but at most $c' - 1$ times) with probability
  $\frac{1}{\tau'}$.

  It is easy to show that from this in all cases follows that
  properties of counting samples are maintained.
\end{proof}

